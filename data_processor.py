"""
Data processing module for the MovieLens dataset.
This module handles the loading and processing of various datasets used in the MovieLens recommendation system.
"""
import streamlit as st
import matplotlib.pyplot as plt
import pandas as pd
import os
import numpy as np
import json
from sklearn.metrics.pairwise import cosine_similarity
from sentence_transformers import SentenceTransformer



"""
Load the pre-trained SentenceTransformer model
This model is used for generating embeddings from text data, such as movie titles and descriptions.
"""
model = SentenceTransformer("all-MiniLM-L6-v2")


""" Dataset file paths """
MOVIES_FILE = "dataset/movies_with_genres_and_intro.csv"
RATINGS_FILE = "dataset/rating.csv"
USERS_FILE = "dataset/users.csv"
TAGS_FILE = "dataset/tag.csv"
GENOME_SCORES_FILE = "dataset/genome_scores.csv"
GENOME_TAGS_FILE = "dataset/genome_tags.csv"
FEEDBACK_FILE = "dataset/feedback.csv" # Autogenerated file to store user feedback



""" Load datasets """
MOVIES_DF = pd.read_csv(MOVIES_FILE, quotechar='"', escapechar='\\', on_bad_lines='skip')
RATINGS_DF = pd.read_csv(RATINGS_FILE)
USERS_DF = pd.read_csv(USERS_FILE, sep="\t")
GENOME_SCORES_DF = pd.read_csv(GENOME_SCORES_FILE)
GENOME_TAGS_DF = pd.read_csv(GENOME_TAGS_FILE)

""" 
Function to transform and prepare data for recommendations 
"""
@st.cache_data(ttl=3600, show_spinner=False, persist=True)
def transform_data():
    # Load datasets
    movies = MOVIES_DF.set_index('movieId')
    ratings = RATINGS_DF
    users = USERS_DF
    genome_scores = GENOME_SCORES_DF
    genome_tags = GENOME_TAGS_DF


    # Build movie-tag relevance matrix (movieId x tagId)
    movie_tag_matrix = genome_scores.pivot(index='movieId', columns='tagId', values='relevance').fillna(0)
    tag_map = dict(zip(genome_tags['tagId'], genome_tags['tag']))
    movie_tag_matrix.columns = [tag_map[int(tagId)] for tagId in movie_tag_matrix.columns]
    
    # get the average rating for each movie
    avg_ratings = RATINGS_DF.groupby('movieId')['rating'].mean()
    
    # Merge movie info into the matrix for easy access
    movie_features = movies[['clean_title', 'year', 'genres', 'wikipedia_intro', 'wikipedia_link']].copy()
    movie_features = movie_features.join(movie_tag_matrix, how='left').fillna(0)
    movie_features['avg_rating'] = avg_ratings
    movie_features['avg_rating'] = movie_features['avg_rating'].fillna(0)

    # Align movies and tag matrix to only common movieIds and same order
    common_ids = movie_features.index.intersection(movie_tag_matrix.index)
    movie_features = movie_features.loc[common_ids].copy()
    movie_tag_matrix = movie_tag_matrix.loc[common_ids]
    movie_vectors = movie_tag_matrix.values  # numpy array for fast similarity

    return {
        "movies": movie_features,
        "ratings": ratings,
        "users": users,
        "tag_map": tag_map,
        "movie_tag_matrix": movie_tag_matrix,
        "movie_vectors": movie_vectors,
        "common_ids": common_ids
    }



def movie_recommendation(user_id, user_prompt, data, n_results=10, weights=None):
    """
    Recommend movies for a user based on their history and a prompt.
    Returns a DataFrame with score breakdowns.
    
        Output:
        DataFrame with columns:
        - movieId: Unique identifier for the movie
        - clean_title: Cleaned title of the movie
        - year: Release year of the movie
        - genres: Genres of the movie
        - final_score: Combined score for the movie based on various factors
        - score_prompt: Score based on the user prompt
        - score_user: Score based on the user's profile (highly rated movies)
        - score_genre: Score based on genre similarity
        - score_year: Score based on the year of the movie
        - score_breakdown: Dictionary with detailed scores and weights used
    """
    movies = data["movies"]
    ratings = data["ratings"]
    movie_tag_matrix = data["movie_tag_matrix"]
    

    if weights is None:
        weights = {
            "prompt": 0.4,
            "user_profile": 0.2,
            "rating": 0.2,
            "genre": 0.1,
            "year": 0.1
        }

    # --- 1. User profile vector (average of tag vectors for highly rated movies) ---
    user_ratings = ratings[ratings["userId"] == user_id]
    high_rated = user_ratings[user_ratings["rating"] >= 4.0]
    if not high_rated.empty:
        user_movie_vectors = movie_tag_matrix.loc[high_rated["movieId"]].values  # Each row represents a high-rated movie's tag relevance vector for the current user
        user_profile_vec = np.average(user_movie_vectors, axis=0, weights=high_rated["rating"])    # Each row represents a tag, the value represents the average relevance score for that tag across the user's highly rated movies
    else:
        user_profile_vec = np.zeros(movie_tag_matrix.shape[1])

    # --- 2. Prompt embedding in tag space (simple: match tags in prompt) ---
    # It basically searches for the words of the prompt and looks for matches on any tag from genome_tags
    prompt_vec = np.zeros(movie_tag_matrix.shape[1])
    prompt_words = set(user_prompt.lower().split())
    tag_list = [tag.lower() for tag in movie_tag_matrix.columns]
    for i, tag in enumerate(tag_list):
        if any(word in tag for word in prompt_words):
            prompt_vec[i] = 1.0
    if np.sum(prompt_vec) > 0:
        prompt_vec /= np.linalg.norm(prompt_vec)

    # --- 3. Similarity scores ---
    # Calculate cosine similarity between the prompt vector, user profile vector
    movie_vectors = movie_tag_matrix.values
    sim_prompt = cosine_similarity([prompt_vec], movie_vectors)[0]
    sim_user = cosine_similarity([user_profile_vec], movie_vectors)[0]

    # --- 4. Genre and year preference ---
    def genre_score(movie_genres):
        """
        Calculate genre similarity score based on user's high-rated movies.
        """
        if high_rated.empty:
            return 0
        user_genres = "|".join(movies.loc[high_rated["movieId"]]["genres"].values)
        user_genres = set(user_genres.split("|"))
        movie_genres = set(movie_genres.split("|"))
        return len(user_genres & movie_genres) / len(user_genres | movie_genres)

    if not high_rated.empty:
        fav_year = int(np.average(movies.loc[high_rated["movieId"]]["year"], weights=high_rated["rating"]))
    else:
        fav_year = None

    def year_score(movie_year):
        if fav_year is None or pd.isna(movie_year):
            return 0
        return 1 - (abs(int(movie_year) - fav_year) / 50)

    # --- 5. Combine scores ---
    movies = movies.copy()
    movies["score_prompt"] = sim_prompt
    movies["score_user"] = sim_user
    movies["score_genre"] = movies["genres"].apply(genre_score)
    movies["score_year"] = movies["year"].apply(year_score)
    movies["score_rating"] = movies["avg_rating"] / 5.0  # Normalize to [0,1]

    movies["final_score"] = (
        weights["prompt"] * movies["score_prompt"] +
        weights["user_profile"] * movies["score_user"] +
        weights["genre"] * movies["score_genre"] +
        weights["year"] * movies["score_year"] +
        weights["rating"] * movies["score_rating"]
    )

    result = movies.sort_values("final_score", ascending=False).head(n_results).copy()
    result["score_breakdown"] = result.apply(
        lambda row: {
            "prompt": row["score_prompt"],
            "user_profile": row["score_user"],
            "rating": row["score_rating"],
            "genre": row["score_genre"],
            "year": row["score_year"],
            "weights": weights
        }, axis=1
    )
    
    result = result.rename(columns={"clean_title": "title"})

    return result.reset_index()[[
        "movieId", "title", "avg_rating", "year", "genres", 
        "final_score", "wikipedia_intro", "wikipedia_link",
        "score_breakdown"
    ]]



def save_recommendation_feedback(userId, movieId, feedback, score_breakdown, feedback_file=FEEDBACK_FILE):
    """
    Save feedback about a recommendation to a CSV file.
    """
    feedback_row = {
        "userId": userId,
        "movieId": movieId,
        "feedback": feedback,
        "score_breakdown": json.dumps(score_breakdown)
    }
    if os.path.exists(feedback_file):
        df = pd.read_csv(feedback_file)
        df = pd.concat([df, pd.DataFrame([feedback_row])], ignore_index=True)
    else:
        df = pd.DataFrame([feedback_row])
    df.to_csv(feedback_file, index=False)
    
    
    
def get_personalized_weights(user_id, default_weights, feedback_file=FEEDBACK_FILE):
    """
    Calculate personalized weights for a user based on all their feedback history.
    Each feedback's weights are weighted by the feedback score.
    Returns a dict of weights.
    """
    import json
    if not os.path.exists(feedback_file):
        return default_weights

    df = pd.read_csv(feedback_file)
    user_feedback = df[df["userId"] == user_id]
    if user_feedback.empty:
        return default_weights

    # Parse weights and feedback
    weights_list = []
    feedback_scores = []
    for _, row in user_feedback.iterrows():
        weights = json.loads(row["score_breakdown"])["weights"]
        weights_list.append(weights)
        feedback_scores.append(float(row["feedback"]))

    weights_df = pd.DataFrame(weights_list)
    feedback_scores = np.array(feedback_scores)

    # Weighted average of weights by feedback score
    if feedback_scores.sum() == 0:
        # Avoid division by zero, just average
        personalized_weights = weights_df.mean().to_dict()
    else:
        personalized_weights = (weights_df.mul(feedback_scores, axis=0).sum() / feedback_scores.sum()).to_dict()

    # Normalize
    total = sum(personalized_weights.values())
    if total > 0:
        personalized_weights = {k: v / total for k, v in personalized_weights.items()}
    return personalized_weights


######### DEBUG ################################################################################################################################################
# data = transform_data()
# print(data)

# test = movie_recommendation(
#     user_id=1,
#     user_prompt="A thrilling action movie with a die hard style",
#     data = transform_data()
#     )

# pd.set_option('display.max_columns', None)  # Show all columns
# pd.set_option('display.width', None)        # No line width limit

# print(test.columns)  # Display all columns in the DataFrame

# print("MovieId", test["movieId"].iloc[0])  
# print("Title", test["title"].iloc[0])  
# print("rating", test["avg_rating"].iloc[0])  
# print("Year", test["year"].iloc[0]) 
# print("Genres", test["genres"].iloc[0])  
# print("final score", test["final_score"].iloc[0]) 
# print("score breakdown", test["score_breakdown"].iloc[0]) 


